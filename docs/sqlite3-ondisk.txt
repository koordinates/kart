sqlite3 -> on-disk

    feature -> blob
        encode as (ordered) JSON now, msgpack/protobufs/avro/thrift/etc later

    tree -> UUIDs:features
        generate or supply UUIDs (v4?)
        we supply for Kx exports, snowdrop client supplies for new features

        subtrees are more efficient
        split on UUID parts?
            ULIDs: lexigraphically sorted: https://github.com/ulid/spec <- allows deriving add-time from ID
            https://blog.2ndquadrant.com/sequential-uuid-generators/ <- rolls over every X days to provide some isolation. C/Java code are both compact. Implement in Python?
            Lots of other implementations of pseudo-UUIDs.
            Keeping the 10MSB of a 32bit timestamp would have ~48 day precision, 11MSB~=24 days. Conversely, rollover based on the LSB to mask? 19bits ~=6 days.

        sqlite has internal rowids for tables, though:
            - not if there's an int pk
            - they're 64bit incrementing integers

    commit -> change
        message; author; date; etc

    ref -> branch (ie. master)



repo layout

.git/
    config
    info/
        attributes              diff/filters/etc)
        exclude                 ==gitignore
my-layer-name.gpkg              ignore'd
my-layer-name/
    meta/
        version                 Snowdrop version
        schema.proto            Protobuf schema
        source.json             Kx source information (sorted JSON)
        gpkg_*.json             dump of gpkg_* tables (sorted JSON)
    tiles/                      TBD.
    features/
        {uuid-prefix}/
            {uuid}.json         feature data (sorted JSON)


checkout:
- create sqlite db
- sync schema
- sync gpkg_*
- sync rows with features/*.json

add:
- create sqlite db
- dump schema
- dump gpkg_*
- dump rows to features/*.json
